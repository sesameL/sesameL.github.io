[{"title":"statistics","date":"2022-09-21T07:48:38.000Z","url":"/2022/09/21/statistics/","tags":[["ML","/tags/ML/"]],"categories":[["undefined",""]],"content":"概率论1.极大似然估计MLE利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值前提：满足独立同分布\\ 对于这个函数：p(x \\mid \\theta) 其中 $ x $ 表示 具体数据 $ \\theta $ 表示模型参数如果 $ \\theta $ 是已知确定的，x是变量，这个函数叫做 概率函数(probability function)，它描述对于不同的样本点 ，其出现概率是多少。如果 $ x $ 是已知确定的，\\theta 是变量，这个函数叫做 似然函数(likelihood function) , 它描述对于不同的模型参数，出现 这个样本点的概率是多少。 e.g.1.有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。想知道罐中白球和黑球的比例前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少? 解：如果第一次抽象的结果记为x1,第二次抽样的结果记为x2….那么样本结果为(x1,x2…..,x100)。这样，我们可以得到如下表达式：P(样本结果|Model) \\begin{aligned} &=P(x 1, x 2, \\ldots, x 100 \\mid \\text { Model }) \\\\ &=P(x 1 \\mid M e l) P(x 2 \\mid M) \\ldots P(x 100 \\mid M) \\\\ &=p^{\\wedge} 70(1-p)^{\\wedge} 30 . \\end{aligned}样本结果出现的可能性最大，也就是使得p^70(1-p)^30值最大，那么我们就可以看成是p的方程，求导即可！ 那么既然事情已经发生了，为什么不让这个出现的结果的可能性最大呢？这也就是最大似然估计的核心。 贝叶斯和最大后验MAP 贝叶斯公式 \\mathrm{P}(\\mathrm{A} \\mid \\mathrm{B})=\\frac{\\mathrm{P}(\\mathrm{B} \\mid \\mathrm{A}) \\mathrm{P}(\\mathrm{A})}{\\mathrm{P}(\\mathrm{B})} 将 $P(B)$ 用全概率公式展开 \\mathrm{P}(\\mathrm{A} \\mid \\mathrm{B})=\\frac{\\mathrm{P}(\\mathrm{B} \\mid \\mathrm{A}) \\mathrm{P}(\\mathrm{A})}{\\mathrm{P}(\\mathrm{B} \\mid \\mathrm{A}) \\mathrm{P}(\\mathrm{A})+\\mathrm{P}(\\mathrm{B} \\mid \\sim \\mathrm{A}) \\mathrm{P}(\\sim \\mathrm{A})} 其中 $ P(A) $ 为先验，为已知值。对于投硬币的例子来看，我们认为（”先验地知道“）θ \\thetaθ取0.5的概率很大，取其他值的概率小一些。可以用一个高斯分布来具体描述这个先验知识，例如假设 $P(\\theta)$ 为均值0.5，方差0.1的高斯函数，$ P(B \\mid A)$ 称似然函数$P(A \\mid B)$ 称为后验 最大后验估计MAP 其中分母为已知值（这是一个可以由数据集得到的值），$P(\\theta)$ 也已知，MAP于MLE的区别就是MAP多乘了一个先验$P(\\theta)$ 朴素贝叶斯 给定训练数据集，其中每个样本x都包括n维特征 $x=\\left(x_1, x_2, \\cdots, x_n\\right)$，类标记集合含有k种类别，即 $y=\\left(y_1, y_2, \\cdots, y_n\\right)$ 此时的后验记为 P\\left(y_k \\mid x\\right)=\\frac{P\\left(x \\mid y_k\\right) \\times P\\left(y_k\\right)}{\\sum_k P\\left(x \\mid y_k\\right) \\times P\\left(y_k\\right)} 朴素贝叶斯算法对条件概率分布作出了独立性的假设，通俗地讲就是说假设各个维度的特征 $ {x_1},{x_2}, \\cdots ,{x_n} $ 互相独立， 所以分子分母的条件概率都能改写为 P\\left(x \\mid y_k\\right)=P\\left(x_1, x_2, \\cdots, x_n \\mid y_k\\right)=\\prod_{i=1}^n P\\left(x_i \\mid y_k\\right) "},{"title":"welcome to my blog","date":"2022-09-21T02:24:41.019Z","url":"/2022/09/21/hello-world/","categories":[["undefined",""]],"content":"This is my first post. Check my GitHub for more info. If you get any problems you can ask me via my Email:se5ame@foxmail.com. Quick StartCreate a new post More info: Writing Run server More info: Server Generate static files More info: Generating Deploy to remote sites More info: Deployment"}]